{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LJ6sjCTcrVOY",
        "outputId": "3943035f-2e57-442e-ad91-9f8d5691c102"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GraphSAGE(pytorch-version)"
      ],
      "metadata": {
        "id": "fKy2T5B0L2Pp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### import Module "
      ],
      "metadata": {
        "id": "UtGYPvkwMEma"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(torch.__version__)"
      ],
      "metadata": {
        "id": "uE2EuBSqNimX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3fbfa5e6-a545-4a6c-cc02-eb9072f77a47"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.13.0+cu116\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyg-lib torch-scatter torch-sparse -f https://data.pyg.org/whl/torch-1.13.0+cu116.html\n",
        "!pip install torch-geometric"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 972
        },
        "id": "UwtIBsdRNUKF",
        "outputId": "8640c734-5185-4947-e2ae-e3c99be92c96"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://data.pyg.org/whl/torch-1.13.0+cu116.html\n",
            "Collecting pyg-lib\n",
            "  Downloading https://data.pyg.org/whl/torch-1.13.0%2Bcu116/pyg_lib-0.1.0%2Bpt113cu116-cp38-cp38-linux_x86_64.whl (1.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.9 MB 12.9 MB/s \n",
            "\u001b[?25hCollecting torch-scatter\n",
            "  Downloading https://data.pyg.org/whl/torch-1.13.0%2Bcu116/torch_scatter-2.1.0%2Bpt113cu116-cp38-cp38-linux_x86_64.whl (9.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 9.4 MB 79.5 MB/s \n",
            "\u001b[?25hCollecting torch-sparse\n",
            "  Downloading https://data.pyg.org/whl/torch-1.13.0%2Bcu116/torch_sparse-0.6.15%2Bpt113cu116-cp38-cp38-linux_x86_64.whl (4.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.6 MB 95.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from torch-sparse) (1.7.3)\n",
            "Requirement already satisfied: numpy<1.23.0,>=1.16.5 in /usr/local/lib/python3.8/dist-packages (from scipy->torch-sparse) (1.21.6)\n",
            "Installing collected packages: torch-sparse, torch-scatter, pyg-lib\n",
            "Successfully installed pyg-lib-0.1.0+pt113cu116 torch-scatter-2.1.0+pt113cu116 torch-sparse-0.6.15+pt113cu116\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.2.0.tar.gz (564 kB)\n",
            "\u001b[K     |████████████████████████████████| 564 kB 4.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from torch-geometric) (4.64.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torch-geometric) (1.21.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from torch-geometric) (1.7.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from torch-geometric) (2.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torch-geometric) (2.23.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.8/dist-packages (from torch-geometric) (3.0.9)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.8/dist-packages (from torch-geometric) (1.0.2)\n",
            "Collecting psutil>=5.8.0\n",
            "  Downloading psutil-5.9.4-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (280 kB)\n",
            "\u001b[K     |████████████████████████████████| 280 kB 92.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from jinja2->torch-geometric) (2.0.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->torch-geometric) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->torch-geometric) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->torch-geometric) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->torch-geometric) (2.10)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->torch-geometric) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->torch-geometric) (3.1.0)\n",
            "Building wheels for collected packages: torch-geometric\n",
            "  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-geometric: filename=torch_geometric-2.2.0-py3-none-any.whl size=773302 sha256=e1bd3cf0e8cc9291e8abeee0d972e511e36e05e341da9d3ea296d408a415b7ba\n",
            "  Stored in directory: /root/.cache/pip/wheels/59/a3/20/198928106d3169865ae73afcbd3d3d1796cf6b429b55c65378\n",
            "Successfully built torch-geometric\n",
            "Installing collected packages: psutil, torch-geometric\n",
            "  Attempting uninstall: psutil\n",
            "    Found existing installation: psutil 5.4.8\n",
            "    Uninstalling psutil-5.4.8:\n",
            "      Successfully uninstalled psutil-5.4.8\n",
            "Successfully installed psutil-5.9.4 torch-geometric-2.2.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "psutil"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### configuration"
      ],
      "metadata": {
        "id": "tyRpJz2Fyjpe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "import pickle\n",
        "import torch\n",
        "\n",
        "def make_logger(name=None):\n",
        "    # https://hwangheek.github.io/2019/python-logging/\n",
        "    logger = logging.getLogger(name) # 로거 객체를 생성\n",
        "    logger.setLevel(logging.DEBUG) # 로그의 레벨\n",
        "    formatter = logging.Formatter(\"%(asctime)s - %(name)s - %(message)s\") # LogRecord의 출력 형태 지정\n",
        "\n",
        "    # Handler는 로그 메시지를 출력하는 역할\n",
        "    console = logging.StreamHandler()\n",
        "    console.setLevel(logging.INFO)\n",
        "    console.setFormatter(formatter)\n",
        "\n",
        "    logger.addHandler(console)\n",
        "    return logger\n",
        "\n",
        "def dump_pickle(address, file):\n",
        "    with open(address, 'wb') as f:\n",
        "        pickle.dump(file, f)\n",
        "\n",
        "def load_pickle(address):\n",
        "    with open(address, 'rb') as f:\n",
        "        data = pickle.load(f)\n",
        "    return data\n",
        "\n",
        "class EarlyStopping:\n",
        "    def __init__(self, patience=10, verbose=False, save_path='checkpoint.pt'):\n",
        "        \"\"\"\n",
        "        :param patience: how many times you will wait before earlystopping\n",
        "        :param save_path: where to save checkpoint\n",
        "        \"\"\"\n",
        "        self.patience = patience\n",
        "        self.verbose = verbose\n",
        "        self.counter = 0\n",
        "        self.best_score = None\n",
        "        self.early_stop = False\n",
        "        self.val_loss_min = float('inf')\n",
        "        self.save_path = save_path\n",
        "\n",
        "    def __call__(self, val_loss, model):\n",
        "        score = -val_loss\n",
        "\n",
        "        if self.best_score is None:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(model, val_loss)\n",
        "        elif score < self.best_score:\n",
        "            self.counter += 1\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(model, val_loss)\n",
        "            self.counter = 0 # reset\n",
        "\n",
        "    def save_checkpoint(self, model, val_loss):\n",
        "        if self.verbose:\n",
        "            print(f\"val loss: ({self.val_loss_min:.6f} -> {val_loss:.6f})\")\n",
        "        torch.save(model.state_dict(), self.save_path)\n",
        "        self.val_loss_min = val_loss"
      ],
      "metadata": {
        "id": "sngXxwOQnsk3"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "MDn9D-pAJnyc"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from tqdm import tqdm\n",
        "from torch_geometric.datasets import Reddit\n",
        "from torch_geometric.data import NeighborSampler\n",
        "from torch_geometric.nn import SAGEConv\n",
        "\n",
        "logger = make_logger(name='graphsage_logger')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd gdrive/MyDrive/GraphSAGE"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R2hIxk33rII3",
        "outputId": "bb16ff4b-02d2-46ad-9101-81e1f58669bb"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: 'gdrive/MyDrive/GraphSAGE'\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Reddit Dataset\n",
        "import os\n",
        "path = os.path.join(os.getcwd(),'data','Reddit')\n",
        "\n",
        "dataset = Reddit(path)\n",
        "data = dataset[0]"
      ],
      "metadata": {
        "id": "CT76D4x1n3Rm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2baec275-6e9d-4a5a-ce83-693a5b41cd17"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://data.dgl.ai/dataset/reddit.zip\n",
            "Extracting /content/data/Reddit/raw/reddit.zip\n",
            "Processing...\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k1cT0SGzsbNi",
        "outputId": "ce2e64bc-1bdf-4f30-c82a-4f65ecc06b0e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data(x=[232965, 602], edge_index=[2, 114615892], y=[232965], train_mask=[232965], val_mask=[232965], test_mask=[232965])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data verification\n",
        "logger.info(f\"Node Feature MAtrix InFo : # Nodes: {data.x.shape[0]}, # Node Features : {data.x.shape[1]}\")\n",
        "\n",
        "# Edge index\n",
        "# Graph Connectivity in Coo Format with shape (2, num_edges)\n",
        "logger.info(f\"Edge index shape : {data.edge_index.shape}\")\n",
        "logger.info(f\"Edge weight: {data.edge_attr}\")\n",
        "\n",
        "# train_mask denotes against which nodes to train\n",
        "print(len(data.train_mask))\n",
        "print(data.train_mask.sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cj9kx7Dsrqmd",
        "outputId": "a46f82ae-0f1e-4158-a96e-643d457d71d3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-12-13 06:38:00,371 - graphsage_logger - Node Feature MAtrix InFo : # Nodes: 232965, # Node Features : 602\n",
            "INFO:graphsage_logger:Node Feature MAtrix InFo : # Nodes: 232965, # Node Features : 602\n",
            "2022-12-13 06:38:00,373 - graphsage_logger - Edge index shape : torch.Size([2, 114615892])\n",
            "INFO:graphsage_logger:Edge index shape : torch.Size([2, 114615892])\n",
            "2022-12-13 06:38:00,376 - graphsage_logger - Edge weight: None\n",
            "INFO:graphsage_logger:Edge weight: None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "232965\n",
            "tensor(153431)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Sampler\n",
        "train_loader = NeighborSampler(\n",
        "    data.edge_index, node_idx=data.train_mask,\n",
        "    sizes=[25, 10], batch_size=1024, shuffle=True, num_workers=12)\n",
        "\n",
        "subgraph_loader = NeighborSampler(\n",
        "    data.edge_index, node_idx=None,\n",
        "    sizes=[-1], batch_size=1024, shuffle=False, num_workers=12)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZjR0I4EsuPm",
        "outputId": "3895b3bf-1920-48e0-f903-c9495fbfc15e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch_geometric/deprecation.py:12: UserWarning: 'data.NeighborSampler' is deprecated, use 'loader.NeighborSampler' instead\n",
            "  warnings.warn(out)\n",
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_loader)\n",
        "print(subgraph_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OVlS1zxXupt-",
        "outputId": "e799ae56-ab2c-4cfd-d586-33af32b7697b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NeighborSampler(sizes=[25, 10])\n",
            "NeighborSampler(sizes=[-1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "next(iter(train_loader))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ev3V6Us8vD62",
        "outputId": "965bc992-f6d1-46bd-f7a7-1fa9f0f1476e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1024,\n",
              " tensor([ 56763, 156564, 104494,  ...,  80749, 195147, 146918]),\n",
              " [EdgeIndex(edge_index=tensor([[10866, 10878, 19709,  ..., 21668, 21671, 21672],\n",
              "          [    0,     0,     0,  ..., 21673, 21673, 21673]]), e_id=tensor([86646886, 34334275, 76882858,  ..., 88386657,  9981250,  7102880]), size=(106277, 21674)),\n",
              "  EdgeIndex(edge_index=tensor([[  457,  1024,  1025,  ..., 21671, 21672, 21673],\n",
              "          [    0,     0,     0,  ...,  1023,  1023,  1023]]), e_id=tensor([20415259, 43538122, 51235531,  ...,  9978656,  7102819, 35764977]), size=(21674, 1024))])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Look\n",
        "batch_size, n_id, adjs = next(iter(train_loader))\n",
        "\n",
        "# 1) batch_size\n",
        "# 현재 batch size를 의미함 (integer)\n",
        "logger.info(f\"Current Batch Size: {batch_size}\")\n",
        "\n",
        "# 2) n_id\n",
        "# 이번 Subgraph에서 사용된 모든 node id\n",
        "# batch_size개의 Row를 예측하기 위해서 이에 대한 1차 이웃 node A개가 필요하고\n",
        "# 1차 이웃 node A개를 위해서는 2차 이웃 node B개가 필요함\n",
        "# n_id.shape = batch_size + A + B\n",
        "logger.info(f\"현재 Subgraph에서 사용된 모든 node id의 개수: {n_id.shape[0]}\")\n",
        "\n",
        "# 3) adjs\n",
        "# 아래와 같이 Layer의 수가 2개이면 adjs는 길이 2의 List가 된다.\n",
        "# head node가 있고 1-hop neighbors와 2-hop neighbors가 있다고 할 때\n",
        "# adjs[1]이 head node와 1-hop neighbors의 관계를 설명하며  (1번째 Layer)\n",
        "# adjs[0]이 1-hop neighbors와 2-hop neighbors의 관계를 설명한다. (2번째 Layer)\n",
        "logger.info(f\"Layer의 수: {len(adjs)}\")\n",
        "\n",
        "# 각 리스트에는 아래와 같은 튜플이 들어있다.\n",
        "# (edge_index, e_id, size)\n",
        "# edge_index: source -> target nodes를 기록한 bipartite edges\n",
        "# e_id: 위 edge_index에 들어있는 index가 Full Graph에서 갖는 node id\n",
        "\n",
        "# size: 위 edge_index에 들어있는 node의 수를 튜플로 나타낸 것으로\n",
        "# head -> 1-hop 관계를 예시로 들면,\n",
        "# head node의 수가 a개, 1-hop node의 수가 b개라고 했을 때\n",
        "# size = (a+b, a)\n",
        "# 또한 target node의 경우 source nodes의 리스트의 시작 부분에 포함되어 있어\n",
        "# skip-connections나 self-loops를 쉽게 사용할 수 있게 되어 있음\n",
        "A = adjs[1].size[0] - batch_size\n",
        "B = adjs[0].size[0] - A - batch_size\n",
        "\n",
        "logger.info(f\"진행 방향: {B}개의 2-hop neighbors ->\"\n",
        "            f\"{A}개의 1-hop neighbors -> {batch_size}개의 Head Nodes\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2U7VH95ru5uX",
        "outputId": "a03ac549-f9e0-44c6-e183-3ae750a74af6"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-12-13 06:38:39,666 - graphsage_logger - Current Batch Size: 1024\n",
            "INFO:graphsage_logger:Current Batch Size: 1024\n",
            "2022-12-13 06:38:39,669 - graphsage_logger - 현재 Subgraph에서 사용된 모든 node id의 개수: 107034\n",
            "INFO:graphsage_logger:현재 Subgraph에서 사용된 모든 node id의 개수: 107034\n",
            "2022-12-13 06:38:39,671 - graphsage_logger - Layer의 수: 2\n",
            "INFO:graphsage_logger:Layer의 수: 2\n",
            "2022-12-13 06:38:39,675 - graphsage_logger - 진행 방향: 85156개의 2-hop neighbors ->20854개의 1-hop neighbors -> 1024개의 Head Nodes\n",
            "INFO:graphsage_logger:진행 방향: 85156개의 2-hop neighbors ->20854개의 1-hop neighbors -> 1024개의 Head Nodes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(adjs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rs5qFTSEw-hk",
        "outputId": "7364a9bd-356e-40ed-cef7-f761e8e5e1a0"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EdgeIndex(edge_index=tensor([[  1024,   1044,   1203,  ..., 107031, 107032, 107033],\n",
            "        [     0,      1,      1,  ...,  21877,  21877,  21877]]), e_id=tensor([ 22854837, 103644544,  74461702,  ...,   9388556,  50869465,\n",
            "         34961078]), size=(107034, 21878)), EdgeIndex(edge_index=tensor([[ 1024,  1025,  1026,  ..., 21875, 21876, 21877],\n",
            "        [    0,     1,     1,  ...,  1023,  1023,  1023]]), e_id=tensor([ 22854837, 113115088,  37512591,  ...,  71936222,  12968253,\n",
            "        101202791]), size=(21878, 1024))]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
      ],
      "metadata": {
        "id": "qZAF5x6cw4X2"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Model\n",
        "class GraphSAGE(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
        "        super(GraphSAGE, self).__init__()\n",
        "\n",
        "        self.num_layers = 2\n",
        "\n",
        "        self.convs = torch.nn.ModuleList()\n",
        "        self.convs.append(SAGEConv(in_channels, hidden_channels))\n",
        "        self.convs.append(SAGEConv(hidden_channels, out_channels))\n",
        "\n",
        "    def forward(self, x, adjs):\n",
        "        for i, (edge_index, _, size) in enumerate(adjs):\n",
        "            x_target = x[:size[1]]  # Target nodes are always placed first.\n",
        "            x = self.convs[i]((x, x_target), edge_index)\n",
        "\n",
        "            # 마지막 Layer는 Dropout을 적용하지 않는다.\n",
        "            if i != self.num_layers - 1:\n",
        "                x = F.relu(x)\n",
        "                x = F.dropout(x, p=0.5, training=self.training)\n",
        "        return x.log_softmax(dim=-1)\n",
        "\n",
        "    def inference(self, x_all):\n",
        "        pbar = tqdm(total=x_all.size(0) * self.num_layers)\n",
        "        pbar.set_description('Evaluating')\n",
        "\n",
        "        # Compute representations of nodes layer by layer, using *all*\n",
        "        # available edges. This leads to faster computation in contrast to\n",
        "        # immediately computing the final representations of each batch.\n",
        "        for i in range(self.num_layers):\n",
        "            xs = []\n",
        "            for batch_size, n_id, adj in subgraph_loader:\n",
        "                edge_index, _, size = adj.to(device)\n",
        "                x = x_all[n_id].to(device)\n",
        "                x_target = x[:size[1]]\n",
        "                x = self.convs[i]((x, x_target), edge_index)\n",
        "                if i != self.num_layers - 1:\n",
        "                    x = F.relu(x)\n",
        "                xs.append(x.cpu())\n",
        "\n",
        "                pbar.update(batch_size)\n",
        "\n",
        "            x_all = torch.cat(xs, dim=0)\n",
        "\n",
        "        pbar.close()\n",
        "        return x_all\n"
      ],
      "metadata": {
        "id": "1N4OHpq3v5MO"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = GraphSAGE(dataset.num_features, 256, dataset.num_classes)\n",
        "model = model.to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "x = data.x.to(device)\n",
        "y = data.y.squeeze().to(device)\n"
      ],
      "metadata": {
        "id": "EMGbDz0Yw8YZ"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def train(epoch):\n",
        "    model.train()\n",
        "\n",
        "    pbar = tqdm(total=int(data.train_mask.sum()))\n",
        "    pbar.set_description(f'Epoch {epoch:02d}')\n",
        "\n",
        "    total_loss = total_correct = 0\n",
        "    for batch_size, n_id, adjs in train_loader:\n",
        "        # `adjs` holds a list of `(edge_index, e_id, size)` tuples.\n",
        "        adjs = [adj.to(device) for adj in adjs]\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        out = model(x[n_id], adjs)\n",
        "        loss = F.nll_loss(out, y[n_id[:batch_size]])\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += float(loss)\n",
        "        total_correct += int(out.argmax(dim=-1).eq(y[n_id[:batch_size]]).sum())\n",
        "        pbar.update(batch_size)\n",
        "\n",
        "    pbar.close()\n",
        "\n",
        "    loss = total_loss / len(train_loader)\n",
        "    approx_acc = total_correct / int(data.train_mask.sum())\n",
        "    return loss, approx_acc\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def test():\n",
        "    model.eval()\n",
        "    out = model.inference(x)\n",
        "\n",
        "    y_true = y.cpu().unsqueeze(-1)\n",
        "    y_pred = out.argmax(dim=-1, keepdim=True)\n",
        "\n",
        "    results = []\n",
        "    for mask in [data.train_mask, data.val_mask, data.test_mask]:\n",
        "        results += [int(y_pred[mask].eq(y_true[mask]).sum()) / int(mask.sum())]\n",
        "    return results\n"
      ],
      "metadata": {
        "id": "cOH-qlORxVhy"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for epoch in range(1, 31):\n",
        "    loss, acc = train(epoch)\n",
        "    print(f'Epoch {epoch:02d}, Loss: {loss:.4f}, Approx. Train: {acc:.4f}')\n",
        "    train_acc, val_acc, test_acc = test()\n",
        "    print(f'Train: {train_acc:.4f}, Val: {val_acc:.4f}, Test: {test_acc:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VAAkwgH5x_VM",
        "outputId": "06708f2e-a378-43bd-be07-236cf4f1a55e"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 01: 100%|██████████| 153431/153431 [00:16<00:00, 9131.56it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 01, Loss: 0.5766, Approx. Train: 0.9314\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 465930/465930 [00:30<00:00, 15515.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 0.9634, Val: 0.9519, Test: 0.9508\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 02: 100%|██████████| 153431/153431 [00:16<00:00, 9240.10it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 02, Loss: 0.5094, Approx. Train: 0.9341\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 465930/465930 [00:30<00:00, 15482.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 0.9641, Val: 0.9528, Test: 0.9517\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 03: 100%|██████████| 153431/153431 [00:16<00:00, 9238.40it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 03, Loss: 0.5552, Approx. Train: 0.9334\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 465930/465930 [00:30<00:00, 15396.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 0.9667, Val: 0.9531, Test: 0.9520\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 04: 100%|██████████| 153431/153431 [00:16<00:00, 9161.21it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 04, Loss: 0.5468, Approx. Train: 0.9354\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 465930/465930 [00:30<00:00, 15477.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 0.9663, Val: 0.9509, Test: 0.9508\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 05: 100%|██████████| 153431/153431 [00:16<00:00, 9166.52it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 05, Loss: 0.5338, Approx. Train: 0.9346\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 465930/465930 [00:30<00:00, 15506.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 0.9681, Val: 0.9530, Test: 0.9533\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 06: 100%|██████████| 153431/153431 [00:16<00:00, 9257.12it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 06, Loss: 0.5386, Approx. Train: 0.9346\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 465930/465930 [00:29<00:00, 15554.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 0.9680, Val: 0.9528, Test: 0.9520\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 07: 100%|██████████| 153431/153431 [00:17<00:00, 8757.41it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 07, Loss: 0.5258, Approx. Train: 0.9354\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 465930/465930 [00:30<00:00, 15405.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 0.9671, Val: 0.9514, Test: 0.9513\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 08: 100%|██████████| 153431/153431 [00:16<00:00, 9110.50it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 08, Loss: 0.5395, Approx. Train: 0.9348\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 465930/465930 [00:30<00:00, 15368.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 0.9677, Val: 0.9527, Test: 0.9516\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 09: 100%|██████████| 153431/153431 [00:16<00:00, 9058.69it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 09, Loss: 0.5800, Approx. Train: 0.9356\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 465930/465930 [00:30<00:00, 15349.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 0.9680, Val: 0.9517, Test: 0.9507\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10: 100%|██████████| 153431/153431 [00:16<00:00, 9144.81it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10, Loss: 0.5072, Approx. Train: 0.9360\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 465930/465930 [00:30<00:00, 15381.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 0.9695, Val: 0.9525, Test: 0.9509\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11: 100%|██████████| 153431/153431 [00:16<00:00, 9029.21it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11, Loss: 0.4930, Approx. Train: 0.9385\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 465930/465930 [00:30<00:00, 15416.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 0.9706, Val: 0.9524, Test: 0.9531\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12: 100%|██████████| 153431/153431 [00:16<00:00, 9146.54it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12, Loss: 0.5410, Approx. Train: 0.9374\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 465930/465930 [00:30<00:00, 15347.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 0.9699, Val: 0.9519, Test: 0.9518\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13: 100%|██████████| 153431/153431 [00:16<00:00, 9052.86it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13, Loss: 0.4940, Approx. Train: 0.9386\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 465930/465930 [00:30<00:00, 15359.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 0.9718, Val: 0.9531, Test: 0.9525\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14: 100%|██████████| 153431/153431 [00:18<00:00, 8403.56it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14, Loss: 0.5590, Approx. Train: 0.9389\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 465930/465930 [00:30<00:00, 15308.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 0.9713, Val: 0.9528, Test: 0.9518\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15: 100%|██████████| 153431/153431 [00:16<00:00, 9051.45it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15, Loss: 0.5261, Approx. Train: 0.9388\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 465930/465930 [00:30<00:00, 15354.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 0.9715, Val: 0.9527, Test: 0.9521\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 16: 100%|██████████| 153431/153431 [00:16<00:00, 9104.57it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16, Loss: 0.5327, Approx. Train: 0.9384\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 465930/465930 [00:30<00:00, 15326.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 0.9712, Val: 0.9515, Test: 0.9524\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 17: 100%|██████████| 153431/153431 [00:16<00:00, 9041.78it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17, Loss: 0.4713, Approx. Train: 0.9400\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 465930/465930 [00:30<00:00, 15294.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 0.9723, Val: 0.9514, Test: 0.9513\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 18: 100%|██████████| 153431/153431 [00:17<00:00, 9019.50it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18, Loss: 0.4891, Approx. Train: 0.9407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 465930/465930 [00:30<00:00, 15363.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 0.9720, Val: 0.9539, Test: 0.9516\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 19: 100%|██████████| 153431/153431 [00:16<00:00, 9148.80it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19, Loss: 0.5029, Approx. Train: 0.9396\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 465930/465930 [00:30<00:00, 15340.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 0.9718, Val: 0.9525, Test: 0.9522\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 20: 100%|██████████| 153431/153431 [00:16<00:00, 9033.30it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20, Loss: 0.4942, Approx. Train: 0.9397\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 465930/465930 [00:30<00:00, 15165.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 0.9724, Val: 0.9523, Test: 0.9514\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 21: 100%|██████████| 153431/153431 [00:16<00:00, 9054.80it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 21, Loss: 0.5234, Approx. Train: 0.9406\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 465930/465930 [00:30<00:00, 15303.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 0.9741, Val: 0.9541, Test: 0.9526\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 22: 100%|██████████| 153431/153431 [00:16<00:00, 9105.12it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 22, Loss: 0.4710, Approx. Train: 0.9416\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 465930/465930 [00:30<00:00, 15332.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 0.9744, Val: 0.9543, Test: 0.9522\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 23: 100%|██████████| 153431/153431 [00:16<00:00, 9092.66it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 23, Loss: 0.5066, Approx. Train: 0.9419\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 465930/465930 [00:30<00:00, 15300.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 0.9742, Val: 0.9544, Test: 0.9527\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 24: 100%|██████████| 153431/153431 [00:16<00:00, 9189.08it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 24, Loss: 0.5067, Approx. Train: 0.9404\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 465930/465930 [00:30<00:00, 15377.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 0.9721, Val: 0.9510, Test: 0.9507\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 25: 100%|██████████| 153431/153431 [00:16<00:00, 9184.25it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 25, Loss: 0.4844, Approx. Train: 0.9413\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 465930/465930 [00:30<00:00, 15494.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 0.9743, Val: 0.9531, Test: 0.9517\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 26: 100%|██████████| 153431/153431 [00:16<00:00, 9103.22it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 26, Loss: 0.4888, Approx. Train: 0.9421\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 465930/465930 [00:30<00:00, 15267.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 0.9720, Val: 0.9517, Test: 0.9508\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 27: 100%|██████████| 153431/153431 [00:16<00:00, 9184.87it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 27, Loss: 0.5573, Approx. Train: 0.9399\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 465930/465930 [00:30<00:00, 15187.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 0.9739, Val: 0.9529, Test: 0.9533\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 28: 100%|██████████| 153431/153431 [00:16<00:00, 9137.31it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 28, Loss: 0.4918, Approx. Train: 0.9414\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 465930/465930 [00:30<00:00, 15348.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 0.9752, Val: 0.9535, Test: 0.9527\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 29: 100%|██████████| 153431/153431 [00:17<00:00, 8988.56it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 29, Loss: 0.4840, Approx. Train: 0.9417\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 465930/465930 [00:30<00:00, 15380.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 0.9743, Val: 0.9527, Test: 0.9521\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 30: 100%|██████████| 153431/153431 [00:16<00:00, 9078.52it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 30, Loss: 0.5294, Approx. Train: 0.9423\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 465930/465930 [00:30<00:00, 15374.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 0.9748, Val: 0.9527, Test: 0.9533\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Fm9tDc7DyHeE"
      },
      "execution_count": 20,
      "outputs": []
    }
  ]
}